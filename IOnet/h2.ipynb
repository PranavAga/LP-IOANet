{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import tqdm\n",
    "# from tqdm.auto import trange, tqdm\n",
    "\n",
    "# import pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# to get CFIAR10 dataset\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# to import pretrained models\n",
    "from transformers import AutoImageProcessor, MobileNetV1Model\n",
    "import timm\n",
    "\n",
    "# import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class ChannelShuffle(nn.Module):\n",
    "\tdef __init__(self, group=1):\n",
    "\t\tassert group > 1\n",
    "\t\tsuper(ChannelShuffle, self).__init__()\n",
    "\t\tself.group = group\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t\"\"\"https://github.com/Randl/ShuffleNetV2-pytorch/blob/master/model.py\n",
    "\t\t\"\"\"\n",
    "\t\tbatchsize, num_channels, height, width = x.data.size()\n",
    "\t\tassert (num_channels % self.group == 0)\n",
    "\t\tchannels_per_group = num_channels // self.group\n",
    "\t\t# reshape\n",
    "\t\tx = x.view(batchsize, self.group, channels_per_group, height, width)\n",
    "\t\t# transpose\n",
    "\t\t# - contiguous() required if transpose() is used before view().\n",
    "\t\t#   See https://github.com/pytorch/pytorch/issues/764\n",
    "\t\tx = torch.transpose(x, 1, 2).contiguous()\n",
    "\t\t# flatten\n",
    "\t\tx = x.view(batchsize, -1, height, width)\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "class identity(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(identity, self).__init__()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn x\n",
    "\n",
    "# based on FB block\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "\tdef __init__(self, in_channels, out_channels, expansion=3):\n",
    "\n",
    "\t\tsuper(DecoderLayer, self).__init__()\n",
    "\t\tself.conv1 = nn.ConvTranspose2d(\n",
    "\t\t\tin_channels, in_channels*expansion, kernel_size=1, stride=1)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(in_channels*expansion)\n",
    "\t\tself.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "\t\tself.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "\t\tself.conv2 = nn.Conv2d(\n",
    "\t\t\tin_channels*expansion, in_channels*expansion, kernel_size=5, padding=2, stride=1)\n",
    "\t\tself.bn2 = nn.BatchNorm2d(in_channels*expansion)\n",
    "\t\tself.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "\t\tself.conv3 = nn.Conv2d(in_channels*expansion,\n",
    "\t\t\t\t\t\t\t   out_channels, kernel_size=1, stride=1)\n",
    "\t\tself.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "\t\t# self.skip_connection = None\n",
    "\n",
    "\t\t# if in_channels != out_channels:\n",
    "\t\t#   self.skip_connection = nn.Conv2d(in_channels, out_channels, kernel_size=5, stride=1)\n",
    "\t\t# else:\n",
    "\t\t#   self.skip_connection = nn.Identity()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tin_x = x\n",
    "\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.bn1(x)\n",
    "\t\tx = self.relu1(x)\n",
    "\n",
    "\t\tx = self.upsample(x)\n",
    "\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.bn2(x)\n",
    "\t\tx = self.relu2(x)\n",
    "\n",
    "\t\tx = self.conv3(x)\n",
    "\t\tx = self.bn3(x)\n",
    "\n",
    "\t\t# TODO add skip connection\n",
    "\n",
    "\t\t# print(\"layer output:\", x.shape)\n",
    "\t\t# print(\"skip connection:\", self.skip_connection(in_x).shape)\n",
    "\n",
    "\t\t# add skip connection\n",
    "\t\t# x = x + self.skip_connection(in_x)\n",
    "\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "# random input\n",
    "x = torch.randn(1, 256, 32, 32)\n",
    "\n",
    "# forward\n",
    "model = DecoderLayer(256, 256)\n",
    "\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the MobileNetV2 model\n",
    "# image_processor = AutoImageProcessor.from_pretrained(\n",
    "# \t\"google/mobilenet_v1_1.0_224\")\n",
    "# mobilenet_v1_model = MobileNetV1Model.from_pretrained(\n",
    "# \t\"google/mobilenet_v1_1.0_224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # a funtion that return the layer of images net in blocks and rest of the model\n",
    "# def get_encoder_layers():\n",
    "# \t# download the model\n",
    "# \timage_processor = AutoImageProcessor.from_pretrained(\n",
    "# \t\t\"google/mobilenet_v1_1.0_224\")\n",
    "# \tmodel = MobileNetV1Model.from_pretrained(\n",
    "# \t\t\"google/mobilenet_v1_1.0_224\")\n",
    "\t\n",
    "# \tmobilenet_seq_blocks = []\n",
    "# \t# block 1 will contain 4 layer of model.layer\n",
    "# \tblock = nn.Sequential(*list(model.layer)[:2])\n",
    "# \tmobilenet_seq_blocks.append(block)\n",
    "# \t# print(\"-\"*30,\"\\n\\nblock 1:\", block)\n",
    "\t\t\n",
    "# \tblock = nn.Sequential(*list(model.layer)[2:4])\n",
    "# \tmobilenet_seq_blocks.append(block)\n",
    "# \t# print(\"-\"*30,\"\\n\\nblock 2:\", block)\n",
    "\n",
    "# \tblock = nn.Sequential(*list(model.layer)[4:8])\n",
    "# \tmobilenet_seq_blocks.append(block)\n",
    "# \t# print(\"-\"*30,\"\\n\\nblock 3:\", block)\t\n",
    "\n",
    "# \tblock = nn.Sequential(*list(model.layer)[8:12])\n",
    "# \tmobilenet_seq_blocks.append(block)\n",
    "# \t# print(\"-\"*30,\"\\n\\nblock 4:\", block)\n",
    "\n",
    "# \tblock = nn.Sequential(*list(model.layer)[12:])\n",
    "# \tmobilenet_seq_blocks.append(block)\n",
    "# \t# print(\"-\"*30,\"\\n\\nblock 5:\", block)\n",
    "\n",
    "# \t# printing the input and output channels of the first and last layers of each block\n",
    "# \t# for i, block in enumerate(mobilenet_seq_blocks):\n",
    "# \t# \t# Extracting the first and last layers of the block\n",
    "# \t# \tfirst_layer = block[0]\n",
    "# \t# \tlast_layer = block[-1]\n",
    "\t\t\n",
    "# \t# \t# Get the input and output channels of the first and last layers\n",
    "# \t# \tinput_channel_first_layer = first_layer.convolution.in_channels\n",
    "# \t# \toutput_channel_last_layer = last_layer.convolution.out_channels\n",
    "\t\t\n",
    "# \t# \tprint(f\"Block {i + 1}:\")\n",
    "# \t# \tprint(\"Input channel of the first layer:\", input_channel_first_layer)\n",
    "# \t# \tprint(\"Output channel of the last layer:\", output_channel_last_layer)\n",
    " \n",
    "# \treturn mobilenet_seq_blocks, model.conv_stem, image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_layers import get_encoder_layers\n",
    "\n",
    "# get encoder layers\n",
    "mobilenet_seq_blocks, conv_stem, image_processor = get_encoder_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FB decoeder block\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion=3):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(in_channels, in_channels*expansion, kernel_size=1, stride=1)\n",
    "        self.bnn1 = nn.BatchNorm2d(in_channels*expansion)\n",
    "        \n",
    "        # nearest neighbor x2\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        # DW conv/ c_in*exp x 5 x 5 x c_in*exp\n",
    "        self.cnn2 = nn.Conv2d(in_channels*expansion, in_channels*expansion, kernel_size=5, padding=2, stride=1)\n",
    "        self.bnn2 = nn.BatchNorm2d(in_channels*expansion)\n",
    "        \n",
    "        \n",
    "        self.cnn3 = nn.Conv2d(in_channels*expansion, out_channels, kernel_size=1, stride=1)\n",
    "        self.bnn3 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_x = x\n",
    "        print(\"input shape:\", x.shape)    \n",
    "        \n",
    "        x = self.cnn1(x)\n",
    "        x = self.bnn1(x)\n",
    "        x = self.relu(x)\n",
    "        print(\"after cnn1 shape:\", x.shape)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        print(\"after upsample shape:\", x.shape)\n",
    "        \n",
    "        x = self.cnn2(x)\n",
    "        x = self.bnn2(x)\n",
    "        x = self.relu(x)\n",
    "        print(\"after cnn2 shape:\", x.shape)\n",
    "        \n",
    "        x = self.cnn3(x)\n",
    "        x = self.bnn3(x)\n",
    "        print(\"after cnn3 shape:\", x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Testings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for decoder block\n",
    "decoder_block = DecoderBlock(256, 128)\n",
    "\n",
    "# random input\n",
    "x = torch.randn(1, 256, 28, 28)\n",
    "\n",
    "# forward\n",
    "y = decoder_block(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send a random image through the model\n",
    "\n",
    "input_img = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# run the first layer \n",
    "input_img = model.conv_stem(input_img)\n",
    "\n",
    "for block_idx, block in enumerate(mobilenet_seq_blocks):\n",
    "\t# input of the block\n",
    "\tprint(f\"\\ninput shape: {input_img.shape}\")\n",
    "\tinput_img = block(input_img)\n",
    "\tprint(f\"Block {block_idx} output shape: {input_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an encoding block takes 512 14 14 and outputs 1024 7 7\n",
    "\n",
    "\t# print(f\"input shape: {x.shape}\")\n",
    " \n",
    "\t# # first layer conv normalisation and relu\n",
    "\t# print(f\"\\nlayer 1: {in_channels} {in_channels}\")\n",
    "\t# x = nn.Conv2d(in_channels, in_channels, kernel_size=(3,3), stride=(1,1), groups=in_channels, bias=False)(x)\n",
    "\t# print(f\"conv1 shape: {x.shape}\")\n",
    " \n",
    "\t# x = nn.BatchNorm2d(in_channels)(x)\n",
    "\t# x = nn.ReLU6()(x)\n",
    "\t# print(f\"norm and act shape: {x.shape}\")\n",
    " \n",
    "\t# # second layer pointwise conv normalisation and relu\n",
    "\t# print(f\"\\nlayer 2: {in_channels} {in_channels}\")\n",
    "\t# x = nn.Conv2d(in_channels, in_channels, kernel_size=(1,1), stride=(1,1), bias=False)(x)\n",
    "\t# print(f\"conv2 shape: {x.shape}\")\n",
    " \n",
    "\t# x = nn.BatchNorm2d(in_channels)(x)\n",
    "\t# x = nn.ReLU6()(x)\n",
    "\t# print(f\"norm and act shape: {x.shape}\")\n",
    " \n",
    "\t# # third layer pointwise conv normalisation and relu\n",
    "\t# print(f\"\\nlayer 3: {in_channels} {in_channels}\")\n",
    "\t# x = nn.Conv2d(in_channels, in_channels, kernel_size=(3,3), stride=(2,2), groups=in_channels, bias=False)(x)\n",
    "\t# print(f\"conv3 shape: {x.shape}\")\n",
    " \n",
    "\t# x = nn.BatchNorm2d(in_channels)(x)\n",
    "\t# x = nn.ReLU6()(x)\n",
    "\t# print(f\"output shape: {x.shape}\")\n",
    " \n",
    "\t# # fourth layer pointwise conv normalisation and relu\n",
    "\t# print(f\"\\nlayer 4: {in_channels} {out_channels}\")\n",
    "\t# x = nn.Conv2d(in_channels, out_channels, kernel_size=(1,1), stride=(1,1), bias=False)(x)\n",
    "\t# print(f\"norm and act shape: {x.shape}\")\n",
    "\t\n",
    "\t# x = nn.BatchNorm2d(out_channels)(x)\n",
    "\t# x = nn.ReLU6()(x)\n",
    "\t# print(f\"output shape: {x.shape}\")\n",
    "  \n",
    "\t# return x\n",
    " \n",
    "def encoding_block(x,in_channels, out_channels):\n",
    "\t\n",
    "\t# each layer in mobilenet_seq_blocks: i want input and output shapes \n",
    "\tfor block_idx, block in enumerate(mobilenet_seq_blocks[-2]):\n",
    "\t\t# input of the block\n",
    "\t\tprint(\"-\"*40,f\"\\n\\n\\ninput shape: {x.shape}\")\n",
    "\t\tprint(f\"Block {block_idx} \\n block description: {block}\")\n",
    "\t\tx = block(x)\n",
    "\t\tprint(f\"Block {block_idx} output shape: {x.shape}\")\n",
    "  \n",
    "\treturn x\n",
    "\n",
    "def decoding_block (x, in_channels, out_channels, expansion=3):\n",
    "\tprint(f\"input shape: {x.shape}\")\n",
    " \n",
    "\t# # first layer conv normalisation and relu\n",
    "\tprint(f\"\\nlayer 1: {in_channels} {in_channels*expansion}\")\n",
    "\tx = nn.Conv2d(in_channels, in_channels*expansion, kernel_size=1, stride=1)(x)\n",
    "\tprint(f\"conv1 shape: {x.shape}\")\n",
    " \n",
    "\tx = nn.BatchNorm2d(in_channels*expansion)(x)\n",
    "\tx = nn.ReLU(inplace=True)(x)\n",
    " \n",
    "\tprint(f\"norm and act shape: {x.shape}\")\n",
    "\t# second layer pointwise conv normalisation and relu\n",
    "\tprint(f\"\\nlayer 2: {in_channels*expansion} {in_channels*expansion}\")\n",
    "\tx = nn.ConvTranspose2d(in_channels*expansion, in_channels*expansion, kernel_size=(3, 3), stride=(2, 2), padding=1, output_padding=1, groups=in_channels*expansion, bias=False)(x)\n",
    "\t# x = nn.ConvTranspose2d(in_channels*expansion, in_channels*expansion, kernel_size=(5, 5), stride=(2, 2), padding=1, bias=False,)(x)\n",
    "\tprint(f\"conv2 shape: {x.shape}\")\n",
    "\t\n",
    "\tx = nn.BatchNorm2d(in_channels*expansion)(x)\n",
    "\tx = nn.ReLU(inplace=True)(x)\n",
    " \n",
    "\tprint(f\"norm and act shape: {x.shape}\")\n",
    "\t# third layer pointwise conv normalisation and relu\n",
    "\tprint(f\"\\nlayer 3: {in_channels*expansion} {out_channels}\")\n",
    "\tx = nn.Conv2d(in_channels*expansion, out_channels, kernel_size=1, stride=1)(x)\n",
    "\tprint(f\"conv3 shape: {x.shape}\")\n",
    "\t\n",
    "\tx = nn.BatchNorm2d(out_channels)(x)\t\n",
    "\tprint(f\"output shape: {x.shape}\")\n",
    "\t\n",
    "\treturn x\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send a random image through the model\n",
    "input_img = torch.randn(1, 512, 14, 14)\n",
    "output_img = torch.randn(1, 512, 14, 14)\n",
    "\n",
    "# run the first layer\n",
    "# end_out = encoding_block(input_img, 512, 1024)\n",
    "dec_out = decoding_block(output_img, 512, 512)\n",
    "\n",
    "# print(f\"final output shape: {end_out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
