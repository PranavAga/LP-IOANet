{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IONetv2 model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import tqdm\n",
    "from tqdm.auto import trange, tqdm\n",
    "\n",
    "# import pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# to get CFIAR10 dataset\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# to import pretrained models\n",
    "from transformers import AutoImageProcessor, MobileNetV1Model\n",
    "import timm\n",
    "\n",
    "# import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fb decoder blocks\n",
    "from get_layersv2 import DecoderBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvtImg(img):\n",
    "    img = img.permute([0, 2, 3, 1])\n",
    "    img = img - img.min()\n",
    "    img = (img / img.max())\n",
    "    return img.numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "def show_examples(x):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    imgs = cvtImg(x)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(imgs[i])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dino ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\transformers\\models\\convnext\\feature_extraction_convnext.py:28: FutureWarning: The class ConvNextFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ConvNextImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, ResNetModel\n",
    "from PIL import Image\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained('Ramos-Ramos/dino-resnet-50')\n",
    "model = ResNetModel.from_pretrained('Ramos-Ramos/dino-resnet-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetEmbeddings(\n",
       "  (embedder): ResNetConvLayer(\n",
       "    (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetStage(\n",
       "  (layers): Sequential(\n",
       "    (0): ResNetBottleNeckLayer(\n",
       "      (shortcut): ResNetShortCut(\n",
       "        (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (layer): Sequential(\n",
       "        (0): ResNetConvLayer(\n",
       "          (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (1): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (2): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (1): ResNetBottleNeckLayer(\n",
       "      (shortcut): Identity()\n",
       "      (layer): Sequential(\n",
       "        (0): ResNetConvLayer(\n",
       "          (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (1): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (2): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (2): ResNetBottleNeckLayer(\n",
       "      (shortcut): Identity()\n",
       "      (layer): Sequential(\n",
       "        (0): ResNetConvLayer(\n",
       "          (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (1): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (2): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (3): ResNetBottleNeckLayer(\n",
       "      (shortcut): Identity()\n",
       "      (layer): Sequential(\n",
       "        (0): ResNetConvLayer(\n",
       "          (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (1): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (2): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (4): ResNetBottleNeckLayer(\n",
       "      (shortcut): Identity()\n",
       "      (layer): Sequential(\n",
       "        (0): ResNetConvLayer(\n",
       "          (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (1): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (2): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (5): ResNetBottleNeckLayer(\n",
       "      (shortcut): Identity()\n",
       "      (layer): Sequential(\n",
       "        (0): ResNetConvLayer(\n",
       "          (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (1): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (2): ResNetConvLayer(\n",
       "          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.stages[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## MobileNetV2: Inverted Residuals and Linear Bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2Model(\n",
       "  (conv_stem): MobileNetV2Stem(\n",
       "    (first_conv): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (conv_3x3): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "      (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (reduce_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer): ModuleList(\n",
       "    (0): MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "        (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "        (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3-4): 2 x MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "        (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
       "        (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6-8): 3 x MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
       "        (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "        (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
       "        (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13-14): 2 x MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "        (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): MobileNetV2InvertedResidual(\n",
       "      (expand_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (conv_3x3): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
       "        (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6()\n",
       "      )\n",
       "      (reduce_1x1): MobileNetV2ConvLayer(\n",
       "        (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_1x1): MobileNetV2ConvLayer(\n",
       "    (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU6()\n",
       "  )\n",
       "  (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MobileNetV2Config, MobileNetV2Model\n",
    "\n",
    "# Initializing a \"mobilenet_v2_1.0_224\" style configuration\n",
    "configuration = MobileNetV2Config()\n",
    "\n",
    "# Initializing a model from the \"mobilenet_v2_1.0_224\" style configuration\n",
    "model = MobileNetV2Model(configuration)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2Stem(\n",
      "  (first_conv): MobileNetV2ConvLayer(\n",
      "    (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "    (activation): ReLU6()\n",
      "  )\n",
      "  (conv_3x3): MobileNetV2ConvLayer(\n",
      "    (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
      "    (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "    (activation): ReLU6()\n",
      "  )\n",
      "  (reduce_1x1): MobileNetV2ConvLayer(\n",
      "    (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# get first layer\n",
    "first_layer = model.conv_stem\n",
    "\n",
    "print(first_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MobileNetV2InvertedResidual(\n",
       "    (expand_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (conv_3x3): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "      (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6()\n",
       "    )\n",
       "    (reduce_1x1): MobileNetV2ConvLayer(\n",
       "      (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_layers = model.layer\n",
    "\n",
    "# mobileNetv2_encoder = nn.ModuleList()\n",
    "list_en = []\n",
    "\n",
    "encoder_layers_idx = [\n",
    "\t[0],\n",
    "    [1,2],\n",
    "\t[3,4,5],\n",
    "\t[6,7,8,9],\n",
    "\t[10,11,12],\n",
    "\t[13,14,15],\n",
    "]\n",
    "\n",
    "for idx, layer in enumerate(encoder_layers_idx):\n",
    "\t# mobileNetv2_encoder.append(nn.Sequential(*[model_layers[i] for i in layer]))\n",
    "\tlist_en.append(nn.Sequential(*[model_layers[i] for i in layer]))\n",
    " \n",
    "list_en[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block 0:\n",
      "  input channels 0: 16\n",
      "  output channels 0: 24\n",
      "\n",
      "Block 1:\n",
      "  input channels 1: 24\n",
      "  output channels 1: 32\n",
      "\n",
      "Block 2:\n",
      "  input channels 2: 32\n",
      "  output channels 2: 64\n",
      "\n",
      "Block 3:\n",
      "  input channels 3: 64\n",
      "  output channels 3: 96\n",
      "\n",
      "Block 4:\n",
      "  input channels 4: 96\n",
      "  output channels 4: 160\n",
      "\n",
      "Block 5:\n",
      "  input channels 5: 160\n",
      "  output channels 5: 320\n",
      "\n",
      "Block 5:\n",
      "  input channels 5: 320\n",
      "  output channels 5: 1280\n"
     ]
    }
   ],
   "source": [
    "for layer_idx, layer in enumerate(list_en):\n",
    "\tprint(f\"\\nBlock {layer_idx}:\")\n",
    "\tprint(f\"  input channels {layer_idx}: {layer[0].expand_1x1.convolution.in_channels}\")\n",
    "\tprint(f\"  output channels {layer_idx}: {layer[-1].reduce_1x1.convolution.out_channels}\")\n",
    "    # break\n",
    "    # if isinstance(layer.convolution, nn.Conv2d):\n",
    "    # print(f\"  Layer {layer_idx}: Input: {layer.convolution.in_channels}, Output: {layer.convolution.out_channels}, Kernel: {layer.convolution.kernel_size}\")\n",
    "    \n",
    "print(f\"\\nBlock {5}:\")\n",
    "list_en.append(model.conv_1x1)\n",
    "# print(list_en[-1])\n",
    "print(f\"  input channels {5}: {list_en[-1].convolution.in_channels}\")\n",
    "print(f\"  output channels {5}: {list_en[-1].convolution.out_channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoderv2_layers():\n",
    "\tlist_en = nn.ModuleList()\n",
    "\tencoder_layers_idx = [\n",
    "\t\t[0],\n",
    "  \t\t[1,2],\n",
    "\t\t[3,4,5],\n",
    "\t\t[6,7,8,9],\n",
    "\t\t[10,11,12],\n",
    "\t\t[13,14,15],\n",
    "\t]\n",
    "\tfor idx, layer in enumerate(encoder_layers_idx):\n",
    "\t\t# list_en.append(nn.Sequential(*[model_layers[i] for i in layer]))\n",
    "\t\tlist_en.append(nn.Sequential(*[model_layers[i] for i in layer]))\n",
    "\tlist_en.append(model.conv_1x1)\n",
    "\treturn list_en, model.conv_stem\n",
    "\n",
    "def get_decoderv2_layers():\n",
    "\tdecoder_layers = nn.ModuleList()\n",
    "\tdecoder_layers.append(DecoderBlock(1280, 320, do_up_sampling=False)) \n",
    "\tdecoder_layers.append(DecoderBlock(320+320, 160, do_up_sampling=False))\n",
    "\tdecoder_layers.append(DecoderBlock(160+160, 96, do_up_sampling=True))\n",
    "\tdecoder_layers.append(DecoderBlock(96+96, 64, do_up_sampling=False))\n",
    "\tdecoder_layers.append(DecoderBlock(64+64, 32, do_up_sampling=True))\n",
    "\tdecoder_layers.append(DecoderBlock(32+32, 24, do_up_sampling=True))\n",
    "\tdecoder_layers.append(DecoderBlock(24+24, 16, do_up_sampling=True))\n",
    "\t\n",
    "\t# a conv layer to get the final output\n",
    "\tout_stem = nn.Sequential(\n",
    "\t\tnn.Sequential(\n",
    "\t\t\tnn.ConvTranspose2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "\t\t\tnn.BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True),\n",
    "\t\t\tnn.ReLU6(),\n",
    "\t\t),\n",
    "\t\tnn.Sequential(\n",
    "\t\t\tnn.ConvTranspose2d(32,32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False,padding=1),\n",
    "\t\t\tnn.BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True),\n",
    "\t\t\tnn.ReLU6(),\n",
    "\t\t),\n",
    "\t\tnn.Sequential(\n",
    "\t\t\tnn.ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2), bias=False, padding=1, output_padding=1),\n",
    "\t\t\tnn.BatchNorm2d(3, eps=0.001, momentum=0.997, affine=True, track_running_stats=True), \n",
    "\t\t)\n",
    "\t)\n",
    " \n",
    "\treturn decoder_layers, out_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 3, 224, 224])\n",
      "First Layer: torch.Size([1, 16, 112, 112])\n",
      "Layer 0: torch.Size([1, 24, 56, 56])\n",
      "Layer 1: torch.Size([1, 32, 28, 28])\n",
      "Layer 2: torch.Size([1, 64, 14, 14])\n",
      "Layer 3: torch.Size([1, 96, 14, 14])\n",
      "Layer 4: torch.Size([1, 160, 7, 7])\n",
      "Layer 5: torch.Size([1, 320, 7, 7])\n",
      "Layer 6: torch.Size([1, 1280, 7, 7])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# forward pass random image 3x224x224\n",
    "input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# get encoder layers\n",
    "ex_enc_list,ex_first_layer = get_encoderv2_layers()\n",
    "\n",
    "# forward pass\n",
    "x = input\n",
    "print(f\"Input: {x.size()}\")\n",
    "\n",
    "# preprocess input\n",
    "x = ex_first_layer(x)\n",
    "print(f\"First Layer: {x.size()}\")\n",
    "\n",
    "for idx, layer in enumerate(ex_enc_list):\n",
    "\tx = layer(x)\n",
    "\tprint(f\"Layer {idx}: {x.size()}\")\n",
    " \n",
    "print()\n",
    "\n",
    "# ex_first_layer\n",
    "# ex_enc_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 16, 112, 112])\n",
      "Output: torch.Size([1, 3, 224, 224])\n",
      "Input: torch.Size([1, 3, 224, 224])\n",
      "Output: torch.Size([1, 16, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "out_stem = nn.Sequential(\n",
    "\t\tnn.Sequential(\n",
    "\t\t\tnn.ConvTranspose2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "\t\t\tnn.BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True),\n",
    "\t\t\tnn.ReLU6(),\n",
    "\t\t),\n",
    "\t\tnn.Sequential(\n",
    "\t\t\tnn.ConvTranspose2d(32,32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False,padding=1),\n",
    "\t\t\tnn.BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True),\n",
    "\t\t\tnn.ReLU6(),\n",
    "\t\t),\n",
    "\t\tnn.Sequential(\n",
    "\t\t\tnn.ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2), bias=False, padding=1, output_padding=1),\n",
    "\t\t\tnn.BatchNorm2d(3, eps=0.001, momentum=0.997, affine=True, track_running_stats=True), \n",
    "\t\t)\n",
    "\t)\n",
    "\n",
    "x_in = torch.randn(1, 16, 112, 112)\n",
    "x = x_in\n",
    "\n",
    "x_out = out_stem(x)\n",
    "\n",
    "print(f\"Input: {x_in.size()}\")\n",
    "print(f\"Output: {x_out.size()}\")\n",
    "\n",
    "x_in = torch.randn(1, 3, 224, 224)\n",
    "x = x_in\n",
    "\n",
    "x_out = model.conv_stem(x)\n",
    "\n",
    "print(f\"Input: {x_in.size()}\")\n",
    "print(f\"Output: {x_out.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Unet, self).__init__()\n",
    "\t\t# get encoder layers\n",
    "\t\tself.encoder_blocks, self.first_layer = get_encoderv2_layers()\n",
    "\t\tself.decoder_blocks, self.last_layer = get_decoderv2_layers()\n",
    "  \n",
    "\tdef forward(self,x):\n",
    "\t\tassert x.shape[1] == 3, \"input image should have 3 channels(nx3x224x224)\"\n",
    "  \n",
    "\t\ttemp_in_x = x\n",
    "\t\tprint(f\"input size: {x.shape}\") \n",
    "\n",
    "\t\tx = self.first_layer(x)\n",
    "\t\tprint(f\"First size: {x.shape}\") \n",
    "  \n",
    "\t\tenc_outputs = []\n",
    "\t\tfor indx, enc_block in enumerate(self.encoder_blocks):\n",
    "\t\t\t\tx = enc_block(x)\n",
    "\t\t\t\tprint(f\"Encoder block {indx} output shape: {x.shape}\")\n",
    "\t\t\t\tenc_outputs.append(x)\n",
    "    \n",
    "\t\tprint(f\"Rep size: {x.shape}\") \n",
    "  \n",
    "\t\tfor indx, dec_block in enumerate(self.decoder_blocks):\n",
    "\t\t\tif indx == 0:\n",
    "\t\t\t\tprint(\"we\")\n",
    "\t\t\t\tx = dec_block(x)\n",
    "\t\t\t\t\n",
    "\t\t\telse:\n",
    "\t\t\t\tx = dec_block(\n",
    "\t\t\t\t\ttorch.cat([x, enc_outputs[len(self.decoder_blocks) - indx - 1]], dim=1))\n",
    "\t\t\tprint(f\"Decoder block {indx} output shape: {x.shape}\")\n",
    "   \n",
    "\t\tx = self.last_layer(x)\n",
    "\t\tprint(f\"Last size: {x.shape}\")\n",
    "  \n",
    "\t\t# attention\n",
    "  \n",
    "\t\treturn x + temp_in_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion=2, do_up_sampling=True):\n",
    "        # TODO: adding skip connections\n",
    "        \"\"\"\n",
    "        Decoder block module.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            expansion (int, optional): Expansion factor. Default is 3.\n",
    "        \"\"\"\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, in_channels *\n",
    "                              expansion, kernel_size=1, stride=1)\n",
    "        self.bnn1 = nn.BatchNorm2d(in_channels*expansion)\n",
    "\n",
    "        # nearest neighbor x2\n",
    "        self.do_up_sampling = do_up_sampling\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        # DW conv/ c_in*exp x 5 x 5 x c_in*exp\n",
    "        self.cnn2 = nn.Conv2d(in_channels*expansion, in_channels *\n",
    "                              expansion, kernel_size=5, padding=2, stride=1)\n",
    "        self.bnn2 = nn.BatchNorm2d(in_channels*expansion)\n",
    "\n",
    "        self.cnn3 = nn.Conv2d(in_channels*expansion,\n",
    "                              out_channels, kernel_size=1, stride=1)\n",
    "        self.bnn3 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.identity = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "\t\t)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the decoder block.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor.\n",
    "        \"\"\"\n",
    "        temp_x = self.identity(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.bnn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self.do_up_sampling:\n",
    "            x = self.upsample(x)\n",
    "            temp_x = self.upsample(temp_x)\n",
    "\n",
    "        x = self.cnn2(x)\n",
    "        x = self.bnn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.cnn3(x)\n",
    "        x = self.bnn3(x)\n",
    "\n",
    "        return x + temp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([1, 3, 224, 224])\n",
      "First size: torch.Size([1, 16, 112, 112])\n",
      "Encoder block 0 output shape: torch.Size([1, 24, 56, 56])\n",
      "Encoder block 1 output shape: torch.Size([1, 32, 28, 28])\n",
      "Encoder block 2 output shape: torch.Size([1, 64, 14, 14])\n",
      "Encoder block 3 output shape: torch.Size([1, 96, 14, 14])\n",
      "Encoder block 4 output shape: torch.Size([1, 160, 7, 7])\n",
      "Encoder block 5 output shape: torch.Size([1, 320, 7, 7])\n",
      "Encoder block 6 output shape: torch.Size([1, 1280, 7, 7])\n",
      "Rep size: torch.Size([1, 1280, 7, 7])\n",
      "we\n",
      "Decoder block 0 output shape: torch.Size([1, 320, 7, 7])\n",
      "Decoder block 1 output shape: torch.Size([1, 160, 7, 7])\n",
      "Decoder block 2 output shape: torch.Size([1, 96, 14, 14])\n",
      "Decoder block 3 output shape: torch.Size([1, 64, 14, 14])\n",
      "Decoder block 4 output shape: torch.Size([1, 32, 28, 28])\n",
      "Decoder block 5 output shape: torch.Size([1, 24, 56, 56])\n",
      "Decoder block 6 output shape: torch.Size([1, 16, 112, 112])\n",
      "Last size: torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "ex_unet = Unet()\n",
    "  \n",
    "# input \n",
    "ex_in_u = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "ex_out_u = ex_unet(ex_in_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
