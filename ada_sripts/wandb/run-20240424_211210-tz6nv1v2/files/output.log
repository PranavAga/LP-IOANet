torch.Size([45, 3, 256, 192]) torch.Size([5, 3, 256, 192]) torch.Size([45, 3, 256, 192]) torch.Size([5, 3, 256, 192])
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/home2/sreenivas88/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home2/sreenivas88/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /home2/sreenivas88/miniconda3/lib/python3.12/site-packages/lpips/weights/v0.1/alex.pth
model size: 969.097MB
  0%|          | 0/5 [00:00<?, ?it/s]
Training started



100%|██████████| 5/5 [00:06<00:00,  1.27s/it]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
  0%|          | 0/5 [00:00<?, ?it/s]
Epoch 0/50: |>train_loss: 13.90278491973877, val_loss: 14.164909362792969, val_accuracy: 0.23191747069358826
Original Image


100%|██████████| 5/5 [00:04<00:00,  1.10it/s]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
  0%|          | 0/5 [00:00<?, ?it/s]
Epoch 1/50: |>train_loss: 13.741809272766114, val_loss: 14.106488227844238, val_accuracy: 0.23852550983428955
Original Image


100%|██████████| 5/5 [00:04<00:00,  1.09it/s]
Epoch 2/50: |>train_loss: 13.929154396057129, val_loss: 14.05624771118164, val_accuracy: 0.2430458515882492
Original Image
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
 20%|██        | 1/5 [00:00<00:03,  1.04it/s]


100%|██████████| 5/5 [00:04<00:00,  1.09it/s]
Epoch 3/50: |>train_loss: 13.843472480773926, val_loss: 14.037667274475098, val_accuracy: 0.24355550110340118
Original Image
Epoch 5/50
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).

100%|██████████| 5/5 [00:04<00:00,  1.09it/s]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Epoch 4/50: |>train_loss: 13.768110847473144, val_loss: 14.158675193786621, val_accuracy: 0.23232035338878632
Original Image
Epoch 6/50

100%|██████████| 5/5 [00:04<00:00,  1.09it/s]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
  0%|          | 0/5 [00:00<?, ?it/s]
Epoch 5/50: |>train_loss: 13.899662208557128, val_loss: 14.209749221801758, val_accuracy: 0.2309558391571045
Original Image


100%|██████████| 5/5 [00:04<00:00,  1.08it/s]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
  0%|          | 0/5 [00:00<?, ?it/s]
Epoch 6/50: |>train_loss: 13.678775596618653, val_loss: 14.412312507629395, val_accuracy: 0.2228693962097168
Original Image


100%|██████████| 5/5 [00:04<00:00,  1.04it/s]
Epoch 7/50: |>train_loss: 13.545474243164062, val_loss: 14.41972541809082, val_accuracy: 0.2180810272693634
Original Image
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
 20%|██        | 1/5 [00:00<00:03,  1.03it/s]

 40%|████      | 2/5 [00:02<00:03,  1.15s/it]
{"AutoImageProcessor": "type", "CoordAtt": "type", "DEVICE": "str", "DecoderBlock": "type", "Image": "module", "MobileNetV1Model": "type", "PIL": "module", "SEED": "int", "SSIM": "ABCMeta", "UnetWithAT": "type", "UnetWithoutAT": "type", "X_test": "Tensor", "X_train": "Tensor", "Y_test": "Tensor", "Y_train": "Tensor", "accuracy": "function", "buffer": "Tensor", "buffer_size": "int", "config": "Config", "folder_path_removed": "str", "folder_path_shadow": "str", "get_decoder_layers": "function", "get_encoder_layers": "function", "get_ipython": "function", "get_loss": "function", "h_sigmoid": "type", "h_swish": "type", "img_removed": "Tensor", "img_shadow": "Tensor", "load_images_from_folder": "function", "loss1": "L1Loss", "loss_layer": "function", "loss_weights": "tuple", "lpips": "module", "lpips_layer": "LPIPS", "model": "DataParallel", "n_images": "int", "nn": "module", "norm_mean": "list", "norm_std": "list", "np": "module", "optimizer": "Adam", "os": "module", "param": "Parameter", "param_size": "int", "plt": "module", "size_all_mb": "float", "torch": "module", "tqdm": "type", "train_dataset": "TensorDataset", "train_loader": "DataLoader", "train_test_split": "function", "training": "function", "transform": "Compose", "transforms": "module", "val_dataset": "TensorDataset", "val_loader": "DataLoader", "wandb": "module"}
torch.Size([3150, 3, 256, 192]) torch.Size([350, 3, 256, 192]) torch.Size([3150, 3, 256, 192]) torch.Size([350, 3, 256, 192])
/home2/sreenivas88/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home2/sreenivas88/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Loading model from: /home2/sreenivas88/miniconda3/lib/python3.12/site-packages/lpips/weights/v0.1/alex.pth
model size: 969.097MB
Training started
Epoch 1/50




























































































































































100%|██████████| 315/315 [05:14<00:00,  1.00it/s]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
  0%|          | 0/315 [00:00<?, ?it/s]
Epoch 0/50: |>train_loss: 14.361082979232545, val_loss: 12.16010570526123, val_accuracy: 0.18883360922336578
Original Image































































































































































100%|██████████| 315/315 [05:19<00:00,  1.02s/it]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Epoch 1/50: |>train_loss: 14.360866555713471, val_loss: 12.224891662597656, val_accuracy: 0.18397197127342224
Original Image
Epoch 3/50





























































































































































100%|██████████| 315/315 [05:16<00:00,  1.01s/it]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
  0%|          | 0/315 [00:00<?, ?it/s]
Epoch 2/50: |>train_loss: 14.361984464857313, val_loss: 12.275386810302734, val_accuracy: 0.18292462825775146
Original Image
















































































































































100%|██████████| 315/315 [05:17<00:00,  1.01s/it]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Epoch 3/50: |>train_loss: 14.362680580502465, val_loss: 12.222396850585938, val_accuracy: 0.1802525520324707
Original Image
Epoch 5/50





























































































































































100%|██████████| 315/315 [05:16<00:00,  1.01s/it]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
  0%|          | 0/315 [00:00<?, ?it/s]
Epoch 4/50: |>train_loss: 14.35839294857449, val_loss: 12.312429428100586, val_accuracy: 0.18379291892051697
Original Image






























































































































































100%|██████████| 315/315 [05:16<00:00,  1.01s/it]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
  0%|          | 0/315 [00:00<?, ?it/s]
Epoch 5/50: |>train_loss: 14.360628930349199, val_loss: 12.09034252166748, val_accuracy: 0.19309361279010773
Original Image






























































































































































100%|██████████| 315/315 [05:16<00:00,  1.01s/it]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
  0%|          | 0/315 [00:00<?, ?it/s]
Epoch 6/50: |>train_loss: 14.363628708370149, val_loss: 12.234196662902832, val_accuracy: 0.18275831639766693
Original Image






























































































































































100%|██████████| 315/315 [05:16<00:00,  1.01s/it]
Epoch 7/50: |>train_loss: 14.362269798157707, val_loss: 12.147137641906738, val_accuracy: 0.18849214911460876
Original Image
Epoch 9/50
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).














































